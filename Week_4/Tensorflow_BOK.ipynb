{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d300e058",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "- 구글에서 개발한 수치 계산과 대규모 머신러닝을 위한 오픈소스 라이브러리\n",
    "- CPU/GPU 모드가 있는데, GPU 모드는 NVIDIA의 그래픽 카드가 없으면 사용할 수 없음\n",
    "- GPU 모드는 CPU의 성능이 아닌 GPU의 성능이 중요\n",
    "\n",
    "## 텐서플로우가 제공하는 것\n",
    "- 핵심 구조는 numpy와 비슷, GPU를 지원\n",
    "- (여러 장치와 서버에 대해)분산 컴퓨팅을 지원\n",
    "- JIT 컴파일러 포함. 속도를 높이고 메모리 사용량을 줄이기 위해 계산 최적화\n",
    "    - 파이썬 함수에서 계산 그래프를 추출한 후 최적화(가지치기) 효율적으로 실행. \n",
    "    - 독립적인 연산을 자동으로 병렬 실행\n",
    "- 계산 그래프는 플랫폼에 중립적인 포맷으로 내보낼 수 있으므로 한 환경에서 텐스플로 모델을 훈련하고 다른 환경에서 실행 가능\n",
    "- 텐서플로는 후진 모드 자동 미분 기능과 RMSProp, Nadam과 같은 고성능 옵티마이저를 제공하므로 모든 종류의 손실함수 쉽게 최소화\n",
    "\n",
    "### 참고 사이트\n",
    "- [TFX](https://tensorflow.org/tfx) \n",
    "- [텐서플로 모델 저장소](https://github.com/tensorflow/models) \n",
    "- [텐서플로 리소스 페이지](https://www.tensorflow.org/resources) : 텐서플로 기반 프로젝트\n",
    "- [텐서플로 기반 프로젝트](https://github.com/jtoy/awesome-tensorflow)\n",
    "- [스택오버플로](https://stackoverflow.com) : 기술적인 질문 시\n",
    "- [텐서플로 깃허브](https://github.com/tensorflow/tensorflow) : 버그를 알리거나 새 기능 요청\n",
    "- [텐서플로 포럼](https://discuss.tensorflow.org) : 일반적인 이야기\n",
    "\n",
    "## Tensor\n",
    "- Tensorflow의 기본 데이터 구조, 다차원 배열. 데이터는 텐서로 표현됨\n",
    "- ndarray(numpy의 다차원 배열)\n",
    "- 스칼라 값도 가질 수 있음(42 같은 단순한 값)\n",
    "-사용자 정의 손실 함수, 사용자 정의 지표, 사용자 정의 층 등을 만들 때 중요. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "336e53af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419f4c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2919 - accuracy: 0.9152\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1423 - accuracy: 0.9574\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1052 - accuracy: 0.9684\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0876 - accuracy: 0.9728\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0749 - accuracy: 0.9762\n",
      "313/313 [==============================] - 0s 830us/step - loss: 0.0690 - accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06904041022062302, 0.9785000085830688]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67d558",
   "metadata": {},
   "source": [
    "# 2. 넘파이와 텐서플로\n",
    "## 2.1. 텐서와 연산\n",
    "- tf.constant()로 텐서 생성 가능, 2행 3열의 실수 행렬을 나타내는 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09abb27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4aaabe",
   "metadata": {},
   "source": [
    "- tf.Tensor는 크기(shape)와 데이터 타입(dtype)을 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3cbdfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ab60004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48951b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 참조\n",
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4551aa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis] # 1열을 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d5f20",
   "metadata": {},
   "source": [
    "- 모든 종류의 텐서 연산이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4802f1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10\n",
    "# tf.add(t, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f6cbc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t) # 원소들을 제곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8904fa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t) # 행렬곱 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "051da259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38, 49],\n",
       "       [60, 79]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[2,3,4],[4,5,6]])\n",
    "b = np.array([[1,3],[4,5],[6,7]])\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7789c670",
   "metadata": {},
   "source": [
    "- 스칼라 값을 가지는 텐서, 이 경우 크기는 비어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e771d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec7ab4",
   "metadata": {},
   "source": [
    "### 텐서플로가 제공하는 연산\n",
    "#### 기본 수학 연산\n",
    "\n",
    "- `tf.add()`\n",
    "  - 두 텐서를 요소별로 더함\n",
    "  - **Example:** `tf.add(x, y)`\n",
    "\n",
    "- `tf.multiply()`\n",
    "  - 두 텐서를 요소별로 곱함\n",
    "  - **Example:** `tf.multiply(x, y)`\n",
    "\n",
    "- `tf.square()`\n",
    "  - 텐서의 각 요소를 제곱함\n",
    "  - **Example:** `tf.square(x)`\n",
    "\n",
    "- `tf.exp()`\n",
    "  - 텐서의 각 요소에 대해 자연로그 밑 e의 지수 함수를 계산\n",
    "  - **Example:** `tf.exp(x)`\n",
    "\n",
    "- `tf.sqrt()`\n",
    "  - 텐서의 각 요소에 대해 제곱근을 계산\n",
    "  - **Example:** `tf.sqrt(x)`\n",
    "\n",
    "#### numpy 제공 연산\n",
    "\n",
    "- `tf.reshape()`\n",
    "  - 텐서를 지정된 모양으로 재구성\n",
    "  - **Example:** `tf.reshape(x, shape)`\n",
    "\n",
    "- `tf.squeeze()`\n",
    "  - 텐서에서 크기가 1인 차원을 제거\n",
    "  - **Example:** `tf.squeeze(x)`\n",
    "\n",
    "- `tf.tile()`\n",
    "  - 텐서를 지정된 횟수만큼 반복\n",
    "  - **Example:** `tf.tile(x, multiples)`\n",
    "\n",
    "#### numpy와 이름이 다른 연산\n",
    "\n",
    "- `tf.reduce_mean() = np.mean()`\n",
    "  - 텐서의 요소들에 대한 평균을 계산\n",
    "  - **Example:** `tf.reduce_mean(x)`\n",
    "\n",
    "- `tf.reduce_sum() = np.sum()`\n",
    "  - 텐서의 요소들에 대한 합을 계산\n",
    "  - **Example:** `tf.reduce_sum(x)`\n",
    "\n",
    "- `tf.reduce_max() = np.max()`\n",
    "  - 텐서의 요소들 중 최대값을 계산\n",
    "  - **Example:** `tf.reduce_max(x)`\n",
    "\n",
    "- `tf.math.log() = np.log()`\n",
    "  - 텐서의 각 요소에 대해 자연로그를 계산\n",
    "  - **Example:** `tf.math.log(x)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430f087",
   "metadata": {},
   "source": [
    "## 2.2. 텐서와 넘파이\n",
    "- numpy 배열로 텐서를 만들 수 있고, 그 반대도 가능\n",
    "- numpy 배열에 텐서플로 연산을 적용할 수 있고 텐서에 numpy 연산을 적용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c47a49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7631903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0671ab85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b507df45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1fa2f",
   "metadata": {},
   "source": [
    "## 2.3. 타입 변환\n",
    "- 타입 변환은 성능 감소 우려\n",
    "- 따라서 자동 타입 변환 X\n",
    "- 호환되지 않는 타입의 텐서로 연산 실행 시 예외 발생\n",
    "    - 실수 + 정수 텐서 연산 불가\n",
    "    - 32비트 실수와 64비트 실수도 연산 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03fb21ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 정수 + 실수 연산 불가\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1234\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1230\u001b[0m   \u001b[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m   \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m maybe_promote_tensors(x, y, force_same_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1234\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1236\u001b[0m   \u001b[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m   \u001b[38;5;66;03m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1240\u001b[0m   \u001b[38;5;66;03m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m   \u001b[38;5;66;03m# informative.\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__r\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m op_name):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1565\u001b[0m, in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1563\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops\u001b[38;5;241m.\u001b[39madd(x, y, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1565\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:522\u001b[0m, in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    520\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 522\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m    524\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6897\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6895\u001b[0m message \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6896\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6897\u001b[0m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_status_to_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "# 정수 + 실수 연산 불가\n",
    "tf.constant(2.) + tf.constant(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c63925a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 32비트와 64비트 연산 불가\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m40.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1234\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1230\u001b[0m   \u001b[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m   \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m maybe_promote_tensors(x, y, force_same_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1234\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1236\u001b[0m   \u001b[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m   \u001b[38;5;66;03m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1240\u001b[0m   \u001b[38;5;66;03m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m   \u001b[38;5;66;03m# informative.\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__r\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m op_name):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1565\u001b[0m, in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1563\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops\u001b[38;5;241m.\u001b[39madd(x, y, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1565\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:522\u001b[0m, in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    520\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 522\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m    524\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6897\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6895\u001b[0m message \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6896\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6897\u001b[0m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_status_to_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "# 32비트와 64비트 연산 불가\n",
    "tf.constant(2.) + tf.constant(40., dtype = tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87716d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타입 변환\n",
    "t2 = tf.constant(40., dtype = tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459069a",
   "metadata": {},
   "source": [
    "## 2.4. 변수\n",
    "- tf.Tensor : 변경 불가능한 객체\n",
    "- tf.Variable : 변경 가능한 객체(신경망의 가중치를 저장, 시간에 따라 변경되는 파라미터에 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "211ea5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f3af4",
   "metadata": {},
   "source": [
    "- tf.Varaible은 tf.Tensor와 동일한 연산 가능\n",
    "- numpy와 호환도 가능\n",
    "- assign 메서드를 사용하여 변숫값을 바꿀 수 있음\n",
    "- assign을 통하지 않은 직접 수정은 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67181768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v) # 바로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edcfdaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42) # 바로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63284aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0, 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c1e6252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0행 0열과 1행 2열을 각각 100., 200.으로 변경\n",
    "v.scatter_nd_update(indices = [[0, 0], [1, 2]], updates = [100., 200.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3058b6",
   "metadata": {},
   "source": [
    "## 2.5. 다른 데이터 구조\n",
    "- 희소 텐서(tf.SparseTensor)\n",
    "    - 대부분 0으로 채워진 텐서를 효율적으로 나타냄\n",
    "    - tf.sparse패키지는 희소 텐서를 위한 연산을 제공\n",
    "- 텐서 배열(tf.TensorArray)\n",
    "    - 텐서의 리스트, 기본적으로 고정된 길이를 가지나 동적으로 바꿀 수 있음\n",
    "    - 리스트에 포함된 모든 텐서는 크기와 데이터 타입이 동일해야 함\n",
    "- 래그드 텐서(tf.RaggedTensor)\n",
    "    - 리스트를 나타냄\n",
    "    - 모든 텐서는 랭크와 데이터 타입이 같아야 하지만 크기는 다를 수 있음\n",
    "    - 텐서의 크기가 달라지는 차원을 래그드 차원이라고 부름\n",
    "    - tf.ragged 패키지는 래그드 텐서를 위한 연산을 제공\n",
    "- 문자열 텐서\n",
    "    - tf.string 타입의 텐서\n",
    "    - 유니코드가 아닌 바이트 문자열을 나타냄\n",
    "    - 자동으로 UTF-8로 인코딩\n",
    "    - 유니코드 포인트를 나타내는 tf.int32 텐서를 사용해 유니코드 문자열을 표현 가능\n",
    "    - tf.strings 패키지는 바이트 문자열, 유니코드 문자열과 이런 텐서 사이의 변환을 위한 연산을 제공\n",
    "    - tf.string은 기본 데이터 타입이므로 문자열의 길이가 텐서 크기에 나타나지 않음\n",
    "    - 유니코드 텐서로 바꾸면 문자열 길이가 텐서 크기에 표현\n",
    "- 집합\n",
    "    - 집합은 일반 텐서 혹은 희소텐서로 표현\n",
    "    - `tf.constant([[1, 2], [3, 4]])`는 두 개의 집합 `{1, 2}`, `{3, 4}`를 나타냄\n",
    "    - 각 집합은 텐서의 마지막 축에 있는 벡터에 의해 표현\n",
    "    - tf.sets 패키지의 연산을 사용해 집합을 다룰 수 있음\n",
    "- 큐\n",
    "    - 단계별로 텐서를 저장\n",
    "    - FIFOQueue : 일반적인 큐\n",
    "    - PriorityQueue : 우선순위 큐\n",
    "    - RandoShuffleQueue : 원소를 섞는 큐\n",
    "    - PaddingFIFOQueue : 패딩을 추가해 크기가 다른 원소의 배치를 만드는 큐\n",
    "    - tf.queue 패키지에 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271ff3a",
   "metadata": {},
   "source": [
    "# 3. 사용자 정의 모델과 훈련 알고리즘\n",
    "## 3.1. 사용자 정의 손실 함수\n",
    "- 후버 손실함수 구현\n",
    "- 레이블과 모델의 예측을 매개변수로 받는 함수를 만들고 텐서플로 연산을 사용해 손실을 모두 담은 텐서를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8a68d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 후버 손실함수\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "# model.compile(loss = huber_fn, optimizer = 'nadam')\n",
    "# model.fit(X_train, y_train, [...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ae7d2",
   "metadata": {},
   "source": [
    "## 3.2 사용자 정의 요소를 가진 모델을 저장하고 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeaf14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('my_model_with_a_custom_loss', custom_objects = {'huber_fn' : huber_fn})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0629b",
   "metadata": {},
   "source": [
    "- 매개변수를 받을 수 있는 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1777f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold = 1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < 1\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = tf.abs(error) - 0.5\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn\n",
    "\n",
    "# model.compile(loss=create_huber(2.0), optimezer = 'nadam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb2d523",
   "metadata": {},
   "source": [
    "- 모델 저장 시 threshold값은 저장 X, 로드 할 때 threshold 값을 지정해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1afea421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.kereas.models.load_model('my_model_with_a_custom_loss_threshold_2', \n",
    "#                                     custom_objects = {'huber_fn' : create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e740b1e",
   "metadata": {},
   "source": [
    "- tf.keras.losses.Loss 클래스를 상속하고 get_config() 메서드를 구현해 해결 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c32efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    # 부모 클래스의 생성자에 전달\n",
    "    def __init__(self, threshold = 1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    # 레이블과 예측을 받고 모든 샘플의 손실을 계산해 반환\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error)  - self.threshold ** 2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    \n",
    "    # 하이퍼파라미터 이름과 같이 매핑된 딕셔너리 반환\n",
    "    # 먼저 부모 클래스의 get_config() 메서드 호출\n",
    "    # 그 다음 딕셔너리에 새로운 파라미터 추가\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return { **base_config, 'threshold' : self.threshold }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c7c3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss = HuberLoss(2.), optimizer='nadam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208b2661",
   "metadata": {},
   "source": [
    "- 모델 로드 시 클래스 이름과 클래스 자체를 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83c3d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('my_model_with_a_custom_loss_class', \n",
    "#                                   custom_objects = {'HuberLoss':HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d17a1",
   "metadata": {},
   "source": [
    "## 3.3 활성화 함수, 초기화, 규제, 제한을 커스터마이징하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "777093cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 활성화 함수\n",
    "# tf.keras.activations.softplus() 와 동일\n",
    "def my_softplus(z):\n",
    "    return tf.math.log(1.0 + tf.exp(z))\n",
    "\n",
    "# 사용자 정의 글로럿 초기화\n",
    "# tf.keras.initializers.glorat_normal() 과 동일\n",
    "def my_glorot_initializer(shape, dtype = tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev = stddev, dtype = dtype)\n",
    "\n",
    "# 사용자 정의 L1 규제\n",
    "# tf.keras.regularizers.l1(0.01)과 동일\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "# 사용자 정의 제한(양수인 가중치만 남기는)\n",
    "# tf.keras.constraints.nonneg()\n",
    "# tf.nn.relu() 와 동일\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights < 0, tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6034fc",
   "metadata": {},
   "source": [
    "- 층 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bed96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(1, activation = my_softplus, \n",
    "                             kernel_initializer = my_glorot_initializer,\n",
    "                             kernel_regularizer = my_l1_regularizer,\n",
    "                             kernel_constraint = my_positive_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0d980",
   "metadata": {},
   "source": [
    "- 이 활성화 함수는 Dense 층의 출력에 적용되고 그 다음 층에 그 결과가 전달\n",
    "- 층의 가중치는 초기화 함수에서 반환된 값으로 초기화\n",
    "- 훈련 스텝마다 가중치가 규제 함수에 전달되어 규제 손실을 계산하고 전체 손실에 추가되어 최종 손실 생성\n",
    "- 제한 함수가 훈련 스텝마다 호출되어 층의 가중치를 제한한 가중치 값으로 바뀜\n",
    "\n",
    "- 함수가 모델과 함께 저장해야 할 파라미터를 가지고 있는 경우 적절한 클래스를 상속한다.\n",
    "- factor 하이퍼 파라미터를 저장하는 L1 규제를 위한 간단한 클래스의 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78cdd3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'factor' : self.factor}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01aa726",
   "metadata": {},
   "source": [
    "## 3.4. 사용자 정의 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c2095",
   "metadata": {},
   "source": [
    "### 손실과 지표의 차이\n",
    "- 손실\n",
    "    - 모델을 훈련하기 위해 경사 하강법에서 사용 및 미분 가능\n",
    "    - 기울기가 모든 곳에서 0이 아니어야 함\n",
    "- 지표\n",
    "    - 모델 평가 시 사용\n",
    "    - 모든 곳에서 기울기가 0이어도 괜찮음\n",
    "    - 미분 불가능해도 됨\n",
    "- 대부분의 경우 사용자 지표 함수를 만드는 것은 사용자 손실 함수를 만드는 것과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04d7ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss = 'mse', optimizer = 'nadam', metrics = [create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d5ad3",
   "metadata": {},
   "source": [
    "- 훈련하는 동안 각 배치에 대해 케라스는 지표를 계산하고 에포크가 시작할 때부터 평균을 기록\n",
    "- 평균은 지표의 평균을 기록하는 것이 아닌 개수를 기록\n",
    "- tf.keras.metrics.Precision 클래스가 하는 일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "364dee79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "620a3970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - 두 번째 배치의 정밀도가 아닌 누적 정밀도를 계산\n",
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b099f8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe41debe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e76d3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states() # 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e618980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    # 지표의 상태를 기록하기 위한 변수를 생성\n",
    "    def __init__(self, threshold = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight('total', initializer='zeros') # 후버 손실의 합\n",
    "        self.count = self.add_weight('count', initializer='zeros') # 처리한 샘플 수\n",
    "    \n",
    "    # 이 클래스를 함수처럼 사용할 때 호출\n",
    "    # 배치의 레이블과 예측을 바탕으로 변수 업데이트\n",
    "    def update_state(self, y_true, y_pred, sample_weight = None):\n",
    "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    \n",
    "    # 최종 결과를 계산하고 반환\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    \n",
    "    # threshold 변수를 모델과 함께 저장\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return { **base_config, \"threshold\" : self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76413c",
   "metadata": {},
   "source": [
    "## 3.5 사용자 정의 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d44cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = tf.keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9ca66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
